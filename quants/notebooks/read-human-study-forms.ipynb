{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Human Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchmetrics\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from matplotlib import pyplot as plt\n",
    "from torchmetrics import Accuracy, F1Score, MetricCollection, Precision, Recall\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study\n",
    "\n",
    "**Note:** Replace `binary` in the definition of `mode` (frist line of the following cell) with `multi`/`open` to run this for the multi-choice or open-ended study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"open\"  # Change to \"multi\" or \"open\" for multi-choice or open-ended study\n",
    "study_file = Path(f\"../../generated-dataset-30_000/human-study/{mode}/study_forms_{mode}.csv\")\n",
    "ground_truth_file = study_file.with_name(study_file.name.replace(\"study_forms_\", \"study_data_\"))\n",
    "form_results = study_file.with_name(study_file.name.replace(\"study_forms_\", \"form_responses_\"))\n",
    "final_results = study_file.with_name(study_file.name.replace(\"study_forms_\", \"final_results_\"))\n",
    "identification_results = study_file.with_name(\n",
    "    study_file.name.replace(\"study_forms_\", \"identification_results_\")\n",
    ")\n",
    "form_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_setup = pd.read_csv(study_file)\n",
    "study_setup[\"study_entry_ids\"] = study_setup[\"study_entry_ids\"].apply(json.loads)\n",
    "study_setup = study_setup.explode(\"study_entry_ids\").set_index(\"study_entry_ids\")\n",
    "study_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT_FILE = \"../../research-430307-ad3438ad46d0.json\"\n",
    "SCOPES = [\n",
    "    \"https://www.googleapis.com/auth/forms.body.readonly\",\n",
    "    \"https://www.googleapis.com/auth/forms.responses.readonly\",\n",
    "]\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "\n",
    "forms_service = build(\"forms\", \"v1\", credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For binary and multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_results = {}\n",
    "\n",
    "for form_id in tqdm(study_setup[\"form_id\"].unique()):\n",
    "    form = forms_service.forms().get(formId=form_id).execute()\n",
    "    responses = forms_service.forms().responses().list(formId=form_id).execute()\n",
    "\n",
    "    if not responses or not responses[\"responses\"]:\n",
    "        print(f\"Form {form_id} has no responses\")\n",
    "        continue\n",
    "    # elif responses:\n",
    "    #     print(f\"Form {form_id} has {len(responses['responses'])} responses\")\n",
    "\n",
    "    question_mapping = {}\n",
    "    for item in form[\"items\"]:\n",
    "        if \"title\" in item and \"Question #\" in item[\"title\"]:\n",
    "            question_number = int(item[\"title\"].split(\"#\")[-1])\n",
    "            # Find the next item which contains the questionItem\n",
    "            next_index = form[\"items\"].index(item) + 1\n",
    "            if next_index < len(form[\"items\"]):\n",
    "                next_item = form[\"items\"][next_index]\n",
    "                if \"questionItem\" in next_item:\n",
    "                    question_id = next_item[\"questionItem\"][\"question\"][\"questionId\"]\n",
    "                    question_mapping[question_id] = question_number\n",
    "                if \"questionItem\" in next_item:\n",
    "                    question_id = next_item[\"questionItem\"][\"question\"][\"questionId\"]\n",
    "                    question_mapping[question_id] = question_number\n",
    "\n",
    "    results = [\n",
    "        {\n",
    "            \"study_entry_ids\": (\n",
    "                -1 if \"00999999\" == elem[\"questionId\"] else question_mapping[elem[\"questionId\"]]\n",
    "            ),\n",
    "            \"answer\": elem[\"textAnswers\"][\"answers\"][0][\"value\"],\n",
    "        }\n",
    "        for elem in responses[\"responses\"][0][\"answers\"].values()\n",
    "    ]\n",
    "    study_entry_df = pd.DataFrame(results)\n",
    "\n",
    "    prolific_id = study_entry_df[study_entry_df[\"study_entry_ids\"] == -1][\"answer\"].item()\n",
    "    study_entry_df = study_entry_df[study_entry_df[\"study_entry_ids\"] != -1]\n",
    "    study_entry_df[\"study_entry_ids\"] -= 1  # Undo the offset for nice presentation\n",
    "    study_entry_df.set_index(\"study_entry_ids\", inplace=True)\n",
    "\n",
    "    collected_results[prolific_id] = study_entry_df\n",
    "\n",
    "all_results = pd.concat(\n",
    "    collected_results.values(), keys=collected_results.keys(), names=[\"prolific_id\"]\n",
    ").reset_index(level=0)\n",
    "all_results.to_csv(form_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_results = {}\n",
    "collected_results_identification = {}\n",
    "\n",
    "for form_id in tqdm(study_setup[\"form_id\"].unique()):\n",
    "    form = forms_service.forms().get(formId=form_id).execute()\n",
    "    responses = forms_service.forms().responses().list(formId=form_id).execute()\n",
    "\n",
    "    if not responses or not responses[\"responses\"]:\n",
    "        print(f\"Form {form_id} has no responses\")\n",
    "        continue\n",
    "    # elif responses:\n",
    "    #     print(f\"Form {form_id} has {len(responses['responses'])} responses\")\n",
    "\n",
    "    questionid_to_answer = {}\n",
    "    questionid_to_indentification_answer = {}\n",
    "    for item in form[\"items\"]:\n",
    "        if \"title\" in item and \"Question #\" in item[\"title\"]:\n",
    "            question_number = int(item[\"title\"].split(\"#\")[-1])\n",
    "            # Find the next item which contains the questionItem\n",
    "            index = form[\"items\"].index(item)\n",
    "            if index + 2 < len(form[\"items\"]):\n",
    "                item_identify = form[\"items\"][index + 1]\n",
    "                item_answer = form[\"items\"][index + 2]\n",
    "                if \"questionGroupItem\" in item_identify:\n",
    "                    for action_index, item in enumerate(item_identify[\"questionGroupItem\"][\"questions\"]):\n",
    "                        question_id = item[\"questionId\"]\n",
    "                        questionid_to_indentification_answer[question_id] = (question_number, action_index)\n",
    "                if \"questionItem\" in item_answer:\n",
    "                    question_id = item_answer[\"questionItem\"][\"question\"][\"questionId\"]\n",
    "                    questionid_to_answer[question_id] = question_number\n",
    "\n",
    "    results = []\n",
    "    results_identification = []\n",
    "    for elem in responses[\"responses\"][0][\"answers\"].values():\n",
    "        q_id = elem[\"questionId\"]\n",
    "        value = elem[\"textAnswers\"][\"answers\"][0][\"value\"]\n",
    "        if q_id == \"00999999\":\n",
    "            prolific_id = value\n",
    "        elif q_id in questionid_to_answer:\n",
    "            results.append(\n",
    "                {\n",
    "                    \"study_entry_ids\": questionid_to_answer[elem[\"questionId\"]],\n",
    "                    \"answer\": value,\n",
    "                }\n",
    "            )\n",
    "        elif q_id in questionid_to_indentification_answer:\n",
    "            question_number, action_index = questionid_to_indentification_answer[q_id]\n",
    "            results_identification.append(\n",
    "                {\n",
    "                    \"study_entry_ids\": question_number,\n",
    "                    \"action_index\": action_index,\n",
    "                    \"answer\": value,\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Question ID {q_id} not found in the mapping\")\n",
    "\n",
    "    study_entry_df = pd.DataFrame(results)\n",
    "    study_entry_df[\"study_entry_ids\"] -= 1  # Undo the offset for nice presentation\n",
    "    study_entry_df.set_index(\"study_entry_ids\", inplace=True)\n",
    "    collected_results[prolific_id] = study_entry_df\n",
    "\n",
    "    id_study_entry_df = pd.DataFrame(results_identification)\n",
    "    id_study_entry_df[\"study_entry_ids\"] -= 1  # Undo the offset for nice presentation\n",
    "    id_study_entry_df.set_index(\"study_entry_ids\", inplace=True)\n",
    "    collected_results_identification[prolific_id] = id_study_entry_df\n",
    "\n",
    "all_results = pd.concat(\n",
    "    collected_results.values(), keys=collected_results.keys(), names=[\"prolific_id\"]\n",
    ").reset_index(level=0)\n",
    "all_results.sort_values(by=[\"study_entry_ids\"], inplace=True)\n",
    "all_results.to_csv(form_results)\n",
    "\n",
    "all_results_identification = pd.concat(\n",
    "    collected_results_identification.values(),\n",
    "    keys=collected_results_identification.keys(),\n",
    "    names=[\"prolific_id\"],\n",
    ").reset_index(level=0)\n",
    "all_results_identification.sort_values(by=[\"study_entry_ids\", \"action_index\"], inplace=True)\n",
    "all_results_identification.to_csv(identification_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.read_csv(form_results, index_col=0)\n",
    "\n",
    "for pid, group in all_results.groupby(\"prolific_id\"):\n",
    "    print(pid + \":\")\n",
    "    for a in group[\"answer\"]:\n",
    "        print(\"    \" + a)\n",
    "\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_open = pd.read_csv(final_results, index_col=0)\n",
    "all_results_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an arbitrary URL to visualize it\n",
    "print(all_results_open.iloc[0][\"responder_uri\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_results = study_setup.join(all_results, how=\"inner\").rename(\n",
    "    columns={\"answer\": \"participant_answer\"}\n",
    ")\n",
    "participant_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv(ground_truth_file, index_col=0)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = participant_results.join(ground_truth, on=\"study_entry_ids\", how=\"inner\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(final_results, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"responder_uri\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"responder_uri\"].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"prolific_id\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prolific_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(df[\"answer\"].value_counts())\n",
    "task = \"multiclass\"\n",
    "avg = \"macro\"\n",
    "\n",
    "metrics = MetricCollection(\n",
    "    {\n",
    "        \"accuracy\": Accuracy(num_classes=num_classes, task=task, average=avg),\n",
    "        \"precision\": Precision(num_classes=num_classes, task=task, average=avg),\n",
    "        \"recall\": Recall(num_classes=num_classes, task=task, average=avg),\n",
    "        \"f1\": F1Score(num_classes=num_classes, task=task, average=avg),\n",
    "    }\n",
    ")\n",
    "\n",
    "to_idx = {\n",
    "    \"yes\": 1,\n",
    "    \"no\": 0,\n",
    "    \"a\": 0,\n",
    "    \"b\": 1,\n",
    "    \"c\": 2,\n",
    "}\n",
    "\n",
    "metrics(\n",
    "    torch.tensor(df[\"answer\"].str.lower().map(to_idx).to_numpy()),\n",
    "    torch.tensor(df[\"participant_answer\"].str.lower().map(to_idx).to_numpy()),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can humans identify the actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_data = pd.read_csv(identification_results, index_col=0).rename(\n",
    "    columns={\"answer\": \"action_classification\"}\n",
    ")\n",
    "df_id_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_data = (\n",
    "    pd.read_csv(study_file.parents[2] / \"test_data.csv\", index_col=0)\n",
    "    .reset_index()\n",
    "    .drop_duplicates(\"sample_id\")\n",
    "    .set_index(\"sample_id\")\n",
    ")\n",
    "all_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = (\n",
    "    df_id_data.reset_index()\n",
    "    .join(ground_truth, on=\"study_entry_ids\", how=\"inner\")\n",
    "    .set_index(\"sample_id\")\n",
    "    .drop(columns=[\"question\", \"answer\"])\n",
    "    .join(all_test_data, on=\"sample_id\", how=\"inner\")\n",
    "    .reset_index()\n",
    "    .set_index([\"sample_id\", \"action_index\"])[[\"action_classification\", \"action_sequence\"]]\n",
    ")\n",
    "df_id[\"action_sequence\"] = df_id[\"action_sequence\"].apply(ast.literal_eval)\n",
    "df_id[\"action_sequence\"] = df_id.apply(lambda row: row[\"action_sequence\"][row.name[1]], axis=1)\n",
    "df_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_to_int = {action: index for index, action in enumerate(df_id[\"action_sequence\"].explode().unique())}\n",
    "action_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = len(df_id)\n",
    "df_id = df_id[df_id[\"action_classification\"] != \"<not recognized>\"]\n",
    "after = len(df_id)\n",
    "f\"Removed {before - after} entries with <not recognized> out of {before} ({(before - after) / before:.2%})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(df: pd.DataFrame) -> dict[str, float]:\n",
    "    res = MetricCollection(\n",
    "        {\n",
    "            \"Accuracy\": torchmetrics.Accuracy(task=\"multiclass\", num_classes=len(action_to_int)),\n",
    "            \"Precision\": torchmetrics.Precision(task=\"multiclass\", num_classes=len(action_to_int)),\n",
    "            \"Recall\": torchmetrics.Recall(task=\"multiclass\", num_classes=len(action_to_int)),\n",
    "            \"F1\": torchmetrics.F1Score(task=\"multiclass\", num_classes=len(action_to_int), average=\"micro\"),\n",
    "        }\n",
    "    )(\n",
    "        torch.from_numpy(df[\"action_classification\"].map(action_to_int).to_numpy(np.int32)),\n",
    "        torch.from_numpy(df[\"action_sequence\"].map(action_to_int).to_numpy(np.int32)),\n",
    "    )\n",
    "    return {key: value.item() for key, value in res.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(df_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "\n",
    "for correct_action, data in df_id.groupby(\"action_sequence\"):\n",
    "    res[correct_action] = get_metrics(data)\n",
    "    res[correct_action][\"count\"] = data.shape[0]\n",
    "\n",
    "df_individual_actions = pd.DataFrame(res).T.sort_index().astype({\"count\": int})\n",
    "df_individual_actions[[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"]] *= 100\n",
    "df_individual_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_context(\"talk\", font_scale=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    data=df_individual_actions.reset_index()\n",
    "    .sort_values(by=\"F1\", ascending=False)\n",
    "    .replace({\"index\": {\"picking something up with both hands\": \"picking [...] both hands\"}}),\n",
    "    x=\"F1\",\n",
    "    y=\"index\",\n",
    "    hue=\"F1\",\n",
    "    palette=sns.color_palette(\"crest_r\", n_colors=len(df_individual_actions)),\n",
    "    legend=False,\n",
    ")\n",
    "plt.xlabel(\"F1 Score [%]\")\n",
    "plt.ylabel(None)\n",
    "plt.xlim(0, 100)\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.savefig(f\"action_classification_{mode}.pdf\", bbox_inches=\"tight\", pad_inches=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id[df_id[\"action_sequence\"] == \"catching a ball\"][\"action_classification\"].value_counts(\n",
    "    normalize=True\n",
    ") * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect all participant IDs that contributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_responses = lambda mode: Path(\n",
    "    f\"../../generated-dataset-30_000/human-study/{mode}/form_responses_{mode}.csv\"\n",
    ")\n",
    "\n",
    "participant_ids = pd.concat(\n",
    "    {\n",
    "        \"binary\": pd.read_csv(path_to_responses(\"binary\"), index_col=0)[\"prolific_id\"].drop_duplicates(),\n",
    "        \"multi\": pd.read_csv(path_to_responses(\"multi\"), index_col=0)[\"prolific_id\"].drop_duplicates(),\n",
    "        \"open\": pd.read_csv(path_to_responses(\"open\"), index_col=0)[\"prolific_id\"].drop_duplicates(),\n",
    "    }\n",
    ")\n",
    "\n",
    "participant_ids.groupby(level=0).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dems_binary = pd.read_csv(\n",
    "    \"../../generated-dataset-30_000/human-study/binary/prolific_demographics_export.csv\"\n",
    ")\n",
    "dems_multi = pd.read_csv(\"../../generated-dataset-30_000/human-study/multi/prolific_demographics_export.csv\")\n",
    "dems_open = pd.read_csv(\"../../generated-dataset-30_000/human-study/open/prolific_demographics_export.csv\")\n",
    "dems = pd.concat([dems_binary, dems_multi, dems_open])\n",
    "\n",
    "# dems = dems[dems[\"Age\"] != \"CONSENT_REVOKED\"]\n",
    "# dems = dems[dems[\"Status\"].isin([\"AWAITING REVIEW\", \"APPROVED\"])]\n",
    "dems = dems[dems[\"Participant id\"].isin(participant_ids)]\n",
    "dems[\"Age\"] = dems[\"Age\"].astype(int)\n",
    "dems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dems.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"crest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 4), squeeze=False)\n",
    "axes = axes[0, :]\n",
    "\n",
    "dems_plot = dems.copy().replace(\n",
    "    {\n",
    "        \"Country of residence\": {\n",
    "            \"United Kingdom\": \"UK\",\n",
    "            \"United States\": \"US\",\n",
    "            \"Canada\": \"CA\",\n",
    "            \"Germany\": \"DE\",\n",
    "            \"Portugal\": \"PT\",\n",
    "            \"Mexico\": \"MX\",\n",
    "            \"Spain\": \"ES\",\n",
    "            \"New Zealand\": \"NZ\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "eth = dems_plot[\"Ethnicity simplified\"]\n",
    "eth = eth[eth != \"DATA_EXPIRED\"]\n",
    "ethnicity_counts = eth.value_counts(normalize=True) * 100\n",
    "sex_counts = dems_plot[\"Sex\"].value_counts(normalize=True) * 100\n",
    "origin_counts = dems_plot[\"Country of residence\"].value_counts(normalize=True) * 100\n",
    "\n",
    "# Aggregate the smallest ones in origin_counts into \"Other\"\n",
    "limit = 5\n",
    "origin_counts[\"Other\"] = origin_counts[origin_counts < limit].sum()\n",
    "origin_counts = origin_counts[origin_counts >= limit]\n",
    "\n",
    "color_palettes = {\n",
    "    # \"Simplified\\nEthnicity\": sns.color_palette(\"Set1\"),\n",
    "    # \"Sex\": sns.color_palette(\"Set2\"),\n",
    "    # \"Country of\\nresidence\": sns.color_palette(\"colorblind\"),\n",
    "    \"Simplified Ethnicity\": sns.color_palette(\"crest\", n_colors=len(ethnicity_counts)),\n",
    "    \"Sex\": sns.color_palette(\"crest\", n_colors=len(sex_counts)),\n",
    "    \"Country of Residence\": sns.color_palette(\"crest\", n_colors=len(origin_counts)),\n",
    "}\n",
    "fontsize = 14\n",
    "\n",
    "bottom_ethnicity = 0\n",
    "for index, value in ethnicity_counts.items():\n",
    "    axes[0].barh(\n",
    "        \"Simplified\\nEthnicity\",\n",
    "        value,\n",
    "        left=bottom_ethnicity,\n",
    "        label=index,\n",
    "        color=color_palettes[\"Simplified Ethnicity\"][ethnicity_counts.index.get_loc(index)],\n",
    "    )\n",
    "    axes[0].text(\n",
    "        bottom_ethnicity + value / 2,\n",
    "        0,\n",
    "        index,\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        color=\"white\",\n",
    "        fontsize=fontsize,\n",
    "        rotation=0 if value > 8 else 90,\n",
    "    )\n",
    "    bottom_ethnicity += value\n",
    "\n",
    "bottom_origin = 0\n",
    "for index, value in origin_counts.items():\n",
    "    axes[0].barh(\n",
    "        \"Country of\\nResidence\",\n",
    "        value,\n",
    "        left=bottom_origin,\n",
    "        label=index,\n",
    "        color=color_palettes[\"Country of Residence\"][origin_counts.index.get_loc(index)],\n",
    "    )\n",
    "    axes[0].text(\n",
    "        bottom_origin + value / 2,\n",
    "        1,\n",
    "        index,\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        color=\"white\",\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "    bottom_origin += value\n",
    "\n",
    "bottom_sex = 0\n",
    "for index, value in sex_counts.items():\n",
    "    axes[0].barh(\n",
    "        \"Sex\",\n",
    "        value,\n",
    "        left=bottom_sex,\n",
    "        label=index,\n",
    "        color=color_palettes[\"Sex\"][sex_counts.index.get_loc(index)],\n",
    "    )\n",
    "    axes[0].text(\n",
    "        bottom_sex + value / 2,\n",
    "        2,\n",
    "        index,\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        color=\"white\",\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "    bottom_sex += value\n",
    "\n",
    "\n",
    "axes[0].set_xlim(0, 100)\n",
    "# axes[0].set_xlabel(\"Percentage\")\n",
    "axes[0].set_xticks([0, 20, 40, 60, 80, 100])\n",
    "axes[0].set_xticklabels([f\"{val.get_text()}%\" for val in axes[0].get_xticklabels()])\n",
    "sns.despine(ax=axes[0], left=True, bottom=True)\n",
    "\n",
    "sns.histplot(\n",
    "    x=dems[\"Age\"],\n",
    "    stat=\"percent\",\n",
    "    ax=axes[1],\n",
    "    element=\"bars\",\n",
    "    bins=[15, 20, 25, 30, 35, 40, 45, 50, 55],\n",
    ")\n",
    "axes[1].xaxis.grid(False)\n",
    "axes[1].set_ylabel(None)\n",
    "axes[1].set_yticks([5, 10, 15, 20, 25, 30])\n",
    "axes[1].set_yticklabels([f\"{val.get_text()}%\" for val in axes[1].get_yticklabels()])\n",
    "sns.despine(ax=axes[1], left=True)\n",
    "\n",
    "plt.tight_layout(w_pad=1, pad=0)\n",
    "\n",
    "plt.savefig(study_file.absolute().parents[1] / \"human_evaluation-demographics.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
