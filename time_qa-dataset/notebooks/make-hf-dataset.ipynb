{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Literal, NamedTuple\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import (\n",
    "    Array2D,\n",
    "    Array3D,\n",
    "    ClassLabel,\n",
    "    Dataset,\n",
    "    DatasetInfo,\n",
    "    Features,\n",
    "    Sequence,\n",
    "    Value,\n",
    ")\n",
    "from pandas.core.groupby import DataFrameGroupBy\n",
    "from tables import open_file\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.contrib.concurrent import process_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure: Full or simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = (Path(\".\").absolute().parents[1] / \"generated-dataset-10_000\" / \"data\").absolute()\n",
    "target_data_repo = \"dasyd/time-qa\"\n",
    "\n",
    "len(list(data_dir.iterdir()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and assembling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample(sample_id=0, question_id=0, trajectory=array([[[-0.0000000e+00,  0.0000000e+00,  9.0687686e-01],\n",
       "        [-6.7598253e-02, -9.7624855e-03,  8.1419015e-01],\n",
       "        [ 6.9608040e-02, -7.2357678e-03,  8.1790030e-01],\n",
       "        ...,\n",
       "        [ 9.2216330e-03,  2.9207093e-01,  1.0123324e+00],\n",
       "        [-1.0229243e-01,  3.1216171e-01,  1.0552542e+00],\n",
       "        [-2.9680135e-02,  3.6213297e-01,  1.0495307e+00]],\n",
       "\n",
       "       [[-1.5695986e-03,  3.3287038e-04,  9.0606552e-01],\n",
       "        [-6.9089182e-02, -9.8003680e-03,  8.1337023e-01],\n",
       "        [ 6.8105243e-02, -6.6510309e-03,  8.1711417e-01],\n",
       "        ...,\n",
       "        [ 3.8956096e-03,  2.9604143e-01,  1.0154035e+00],\n",
       "        [-1.0466182e-01,  3.1318346e-01,  1.0573907e+00],\n",
       "        [-3.6545765e-02,  3.6466584e-01,  1.0536150e+00]],\n",
       "\n",
       "       [[-3.1320225e-03,  8.3422964e-04,  9.0520048e-01],\n",
       "        [-7.0561066e-02, -9.7233178e-03,  8.1248724e-01],\n",
       "        [ 6.6613667e-02, -5.9788004e-03,  8.1629044e-01],\n",
       "        ...,\n",
       "        [-2.2514353e-03,  3.0089089e-01,  1.0183095e+00],\n",
       "        [-1.0651734e-01,  3.1426182e-01,  1.0596598e+00],\n",
       "        [-4.3517634e-02,  3.6790183e-01,  1.0573784e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.1290059e-01,  4.1972452e-01,  9.1293764e-01],\n",
       "        [-2.8324315e-01,  3.9731503e-01,  8.2446462e-01],\n",
       "        [-1.5204284e-01,  4.3760949e-01,  8.1916988e-01],\n",
       "        ...,\n",
       "        [-1.3826838e-01,  6.6111463e-01,  9.9372017e-01],\n",
       "        [-4.6892816e-01,  4.9210256e-01,  1.0031674e+00],\n",
       "        [-2.1479821e-01,  7.2216576e-01,  1.0124954e+00]],\n",
       "\n",
       "       [[-2.1985306e-01,  4.2103457e-01,  9.1677940e-01],\n",
       "        [-2.8981337e-01,  3.9717117e-01,  8.2839501e-01],\n",
       "        [-1.5861249e-01,  4.3744138e-01,  8.2301462e-01],\n",
       "        ...,\n",
       "        [-1.3282846e-01,  6.5083462e-01,  9.8305196e-01],\n",
       "        [-4.7610176e-01,  4.9753374e-01,  9.9834090e-01],\n",
       "        [-2.0856790e-01,  7.1554840e-01,  9.9536461e-01]],\n",
       "\n",
       "       [[-2.2659476e-01,  4.2116159e-01,  9.1723335e-01],\n",
       "        [-2.9618329e-01,  3.9663002e-01,  8.2876509e-01],\n",
       "        [-1.6504441e-01,  4.3711174e-01,  8.2362068e-01],\n",
       "        ...,\n",
       "        [-1.2710191e-01,  6.4022839e-01,  9.6929449e-01],\n",
       "        [-4.8494577e-01,  5.0202930e-01,  9.8926669e-01],\n",
       "        [-2.0158806e-01,  7.0829648e-01,  9.7405303e-01]]], dtype=float32), action_sequence=[{'start': 0.0, 'end': 4.0, 'action': 'holding a baby', 'action_sentence': 'The person is starting the sequence with holding a baby'}, {'start': 4.0, 'end': 8.0, 'action': 'shaking hands', 'action_sentence': 'We see the person engaging in shaking hands'}, {'start': 8.0, 'end': 12.0, 'action': 'holding a baby', 'action_sentence': 'The activity holding a baby can be observed'}, {'start': 12.0, 'end': 16.0, 'action': 'running', 'action_sentence': 'The last action is running'}], textual_description='The person is starting the sequence with holding a baby from 0:0.0 to 0:4.0 (4.0 seconds total). We see the person engaging in shaking hands. This action is starting at 0:4.0 and happens until 0:8.0, meaning the engagement in this is for 4.0 seconds. The activity holding a baby can be observed from 0:8.0 to 0:12.0 (4.0 seconds total). The last action is running from 0:12.0 to 0:16.0 (for 4.0 seconds).', question_type='count_open', question='How often does the person undertake running?', answer_type='open', answer='1', options=None, correct_option='1')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Sample(NamedTuple):\n",
    "    sample_id: int\n",
    "    question_id: int\n",
    "    trajectory: torch.Tensor\n",
    "    action_sequence: dict[str, Any]\n",
    "    textual_description: str\n",
    "    question_type: str\n",
    "    question: str\n",
    "    answer_type: str\n",
    "    answer: str\n",
    "    options: dict[str, str | bool] | None\n",
    "    correct_option: str\n",
    "\n",
    "\n",
    "def get_for(num: int):\n",
    "    path = data_dir / str(num)\n",
    "    with open_file(path / \"data.hdf5\", \"r\") as hdf5_file:\n",
    "        trajectory = hdf5_file.root[\"joints\"][:].astype(\"float32\")\n",
    "\n",
    "    with open(path / \"data.json\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    return [\n",
    "        Sample(\n",
    "            sample_id=num,\n",
    "            question_id=question_id,\n",
    "            trajectory=trajectory,\n",
    "            action_sequence=data[\"prompt_sequence\"],\n",
    "            textual_description=data[\"textual_description\"],\n",
    "            question_type=qa_pair[\"question_type\"],\n",
    "            question=qa_pair[\"question\"],\n",
    "            answer_type=qa_pair[\"answer_type\"],\n",
    "            answer=qa_pair[\"answer\"],\n",
    "            options=qa_pair[\"options\"],  # can be None\n",
    "            correct_option=qa_pair[\"correct_option\"],\n",
    "        )\n",
    "        for question_id, qa_pair in enumerate(data[\"qa_pairs\"])\n",
    "    ]\n",
    "\n",
    "\n",
    "next(iter(get_for(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:09<00:00, 1046.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = sorted([int(path.name) for path in data_dir.glob(\"*\") if (path / \"data.hdf5\").exists()])\n",
    "\n",
    "# Some file may only be partially written, we ignore them\n",
    "for num in tqdm(all_ids[:]):\n",
    "    try:\n",
    "        with open_file(data_dir / str(num) / \"data.hdf5\", \"r\") as hdf5_file:\n",
    "            hdf5_file.root[\"joints\"]\n",
    "    except Exception:\n",
    "        print(f\"Error in {num}, ignoring\")\n",
    "        all_ids.remove(num)\n",
    "\n",
    "len(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 1000, 1000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# For a predefined split:\n",
    "# def get_ids_in_split(split: str) -> list[int]:\n",
    "#     with open(data_dir.parent / f\"{split}.json\", \"r\") as json_file:\n",
    "#         return {entry[\"org_idx\"] for entry in json.load(json_file)}\n",
    "# ids_in_split = {split: get_ids_in_split(split) for split in splits}\n",
    "\n",
    "# For a random split:\n",
    "train = 0.8\n",
    "val = 0.10\n",
    "test = 0.10\n",
    "ids_in_split = {\n",
    "    \"train\": sorted(all_ids[: int(train * len(all_ids))]),\n",
    "    \"val\": sorted(all_ids[int(train * len(all_ids)) : int((train + val) * len(all_ids))]),\n",
    "    \"test\": sorted(all_ids[int((train + val) * len(all_ids)) :]),\n",
    "}\n",
    "\n",
    "assert len(all_ids)\n",
    "assert len(set([*ids_in_split[\"train\"], *ids_in_split[\"val\"], *ids_in_split[\"test\"]])) == len(all_ids)\n",
    "\n",
    "len(ids_in_split[\"train\"]), len(ids_in_split[\"val\"]), len(ids_in_split[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_info(task: Literal[\"binary\", \"open\", \"multi\"]):\n",
    "    base_features = {\n",
    "        \"sample_id\": Value(\"int32\"),\n",
    "        \"question_id\": Value(\"int32\"),\n",
    "        \"trajectory\": Array3D(dtype=\"float32\", shape=next(iter(get_for(0))).trajectory.shape),\n",
    "        \"action_sequence\": Sequence(\n",
    "            Features(\n",
    "                {\n",
    "                    \"start\": Value(\"float32\"),\n",
    "                    \"end\": Value(\"float32\"),\n",
    "                    \"action\": Value(\"string\"),\n",
    "                    \"action_sentence\": Value(\"string\"),\n",
    "                }\n",
    "            ),\n",
    "            length=4,\n",
    "        ),\n",
    "        \"textual_description\": Value(\"string\"),\n",
    "        \"question_type\": Value(\"string\"),\n",
    "        \"question\": Value(\"string\"),\n",
    "        \"answer_type\": Value(\"string\"),\n",
    "        \"answer_text\": Value(\"string\"),  # That's the answer in text form, always present\n",
    "    }\n",
    "\n",
    "    match task:\n",
    "        case \"binary\":\n",
    "            feat_type = Features(\n",
    "                base_features | {\"answer\": ClassLabel(names=[\"true\", \"false\"], num_classes=2)}\n",
    "            )\n",
    "\n",
    "        case \"multi\":\n",
    "            feat_type = Features(\n",
    "                base_features\n",
    "                | {\n",
    "                    \"answer\": ClassLabel(num_classes=3),\n",
    "                    \"options_sequence\": Sequence(Value(\"string\"), length=3),\n",
    "                    \"options\": Features(\n",
    "                        {\n",
    "                            \"A\": Value(\"string\"),\n",
    "                            \"B\": Value(\"string\"),\n",
    "                            \"C\": Value(\"string\"),\n",
    "                        }\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        case \"open\":\n",
    "            feat_type = Features(base_features | {\"answer_text\": Value(\"string\")})\n",
    "\n",
    "    return DatasetInfo(features=feat_type)\n",
    "\n",
    "\n",
    "def get_all(ids: set[int]) -> pd.DataFrame:\n",
    "    # Using process_map to automatically manage the progress bar with executor.map\n",
    "    results = process_map(get_for, ids, max_workers=None, chunksize=1, total=len(ids))\n",
    "    return pd.DataFrame([elem._asdict() for sublist in results for elem in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_grouped_df_to_hub(\n",
    "    df_group: DataFrameGroupBy,\n",
    "    split: Literal[\"test\", \"val\", \"train\"],\n",
    "    limit_task: list[Literal[\"open\", \"multi\", \"binary\"]],\n",
    "    token: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Takes a grouped DataFrame, feature types, dataset info, and a Hugging Face authentication token,\n",
    "    then pushes each group to the Hugging Face Hub under specified configurations.\n",
    "\n",
    "    :param df_group: Grouped Pandas DataFrame object.\n",
    "    :param feat_type: Feature type for the dataset.\n",
    "    :param info: Information about the dataset.\n",
    "    :param token: Hugging Face authentication token.\n",
    "    \"\"\"\n",
    "    for name, group in df_group:\n",
    "        if name not in limit_task:\n",
    "            continue\n",
    "        print(f\"Group Name: {name}\")\n",
    "\n",
    "        group = group.rename(columns={\"answer\": \"answer_text\"})\n",
    "\n",
    "        match name:\n",
    "            case \"binary\":\n",
    "                group[\"answer\"] = (group[\"correct_option\"] == \"A\").astype(int)\n",
    "                group = group.drop(columns=[\"options\"])\n",
    "\n",
    "            case \"multi\":\n",
    "                mapping = {\"A\": 0, \"B\": 1, \"C\": 2}\n",
    "                group[\"answer\"] = [mapping[option] for option in group[\"correct_option\"]]\n",
    "\n",
    "                group[\"options_sequence\"] = group[\"options\"].apply(lambda x: list(x.values()))\n",
    "\n",
    "            case \"open\":\n",
    "                group = group.drop(columns=[\"options\"])\n",
    "\n",
    "        group = group.drop(columns=[\"correct_option\"])\n",
    "\n",
    "        lst_dict = group.to_dict(orient=\"records\")\n",
    "\n",
    "        info = make_info(name)\n",
    "\n",
    "        # Create a dataset from the list of dictionaries and push it to the hub\n",
    "        dataset = Dataset.from_list(lst_dict, info=info, split=split)\n",
    "        dataset.push_to_hub(\n",
    "            target_data_repo,\n",
    "            config_name=name,\n",
    "            token=token,\n",
    "            split=split,\n",
    "        )\n",
    "\n",
    "        print(f\"Pushed to huggingface: {target_data_repo}/{split}/{name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persisting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 723.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Name: binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 3/3 [00:01<00:00,  1.75ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:11<00:00, 11.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushed to huggingface: dasyd/time-qa/val/binary\n",
      "Group Name: multi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:01<00:00,  1.82ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:06<00:00,  6.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushed to huggingface: dasyd/time-qa/val/multi\n",
      "Group Name: open\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:01<00:00,  1.75ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:06<00:00,  6.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushed to huggingface: dasyd/time-qa/val/open\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 680.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Name: binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 3/3 [00:01<00:00,  1.90ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:08<00:00,  8.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushed to huggingface: dasyd/time-qa/test/binary\n",
      "Group Name: multi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:01<00:00,  1.83ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:06<00:00,  6.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushed to huggingface: dasyd/time-qa/test/multi\n",
      "Group Name: open\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:01<00:00,  1.85ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:06<00:00,  6.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushed to huggingface: dasyd/time-qa/test/open\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:11<00:00, 690.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Name: binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:02<00:00,  1.84ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:02<00:00,  1.88ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:02<00:00,  1.73ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:02<00:00,  1.68ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:02<00:00,  1.68ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 5/5 [00:58<00:00, 11.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushed to huggingface: dasyd/time-qa/train/binary\n",
      "Group Name: multi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:02<00:00,  1.55ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:02<00:00,  1.38ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:02<00:00,  1.40ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 3/3 [00:41<00:00, 13.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushed to huggingface: dasyd/time-qa/train/multi\n",
      "Group Name: open\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:02<00:00,  1.39ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:02<00:00,  1.44ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:02<00:00,  1.44ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 3/3 [00:45<00:00, 15.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushed to huggingface: dasyd/time-qa/train/open\n"
     ]
    }
   ],
   "source": [
    "splits = [\"val\", \"test\", \"train\"]\n",
    "\n",
    "for s in splits:\n",
    "    _df = get_all(ids_in_split[s])\n",
    "    _df_group = _df.groupby(\"answer_type\")\n",
    "\n",
    "    push_grouped_df_to_hub(_df_group, split=s, limit_task=[\"binary\", \"multi\", \"open\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to first run:\n",
    "\n",
    "```shell\n",
    "huggingface-cli login\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test if it works (this re-downloads the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 11695/11695 [00:05<00:00, 2239.31 examples/s]\n",
      "Setting num_proc from 2 back to 1 for the val split to disable multiprocessing as it only contains one shard.\n",
      "Generating val split: 100%|██████████| 1416/1416 [00:00<00:00, 1578.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from datasets import VerificationMode, concatenate_datasets, load_dataset\n",
    "from lightning.pytorch import LightningDataModule\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class TimeQADataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        task: Literal[\"binary\", \"multi\", \"open\"],\n",
    "        batch_size: int = 32,\n",
    "        repo: str = target_data_repo,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.task = task\n",
    "        self.batch_size = batch_size\n",
    "        self.repo = repo\n",
    "\n",
    "    def _load_dataset_split(self, splits: list[str]):\n",
    "        \"\"\"Workaround to overcome the missing hf implementation of only dowloading the split shards\"\"\"\n",
    "        dataset = load_dataset(\n",
    "            self.repo,\n",
    "            self.task,\n",
    "            data_dir=self.task,\n",
    "            data_files={split: f\"{split}-*\" for split in splits},\n",
    "            verification_mode=VerificationMode.NO_CHECKS,\n",
    "            num_proc=len(splits),\n",
    "        )\n",
    "        dataset.set_format(type=\"torch\", columns=[\"trajectory\"], output_all_columns=True)\n",
    "        return dataset\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        # Download all, since only this is run on the main process\n",
    "        self._load_dataset_split([\"train\", \"val\", \"test\"])\n",
    "\n",
    "    def setup(self, stage: str) -> None:\n",
    "        if stage == \"fit\":\n",
    "            self.dataset = self._load_dataset_split([\"train\", \"val\"])\n",
    "        elif stage == \"test\":\n",
    "            self.dataset = self._load_dataset_split([\"test\"])\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.dataset[\"train\"], batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.dataset[\"val\"], batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.dataset[\"test\"], batch_size=self.batch_size)\n",
    "\n",
    "    def all_splits(self) -> Dataset:\n",
    "        return concatenate_datasets(self._load_dataset_split([\"train\", \"val\", \"test\"]).values())\n",
    "\n",
    "\n",
    "module = TimeQADataModule(task=\"multi\", batch_size=3)\n",
    "module.prepare_data()\n",
    "module.setup(\"fit\")\n",
    "# module.setup(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trajectory',\n",
       " 'trajectory_rot6d',\n",
       " 'sample_id',\n",
       " 'question_id',\n",
       " 'action_sequence',\n",
       " 'textual_description',\n",
       " 'question_type',\n",
       " 'question',\n",
       " 'answer_type',\n",
       " 'answer_text',\n",
       " 'options',\n",
       " 'answer',\n",
       " 'options_sequence']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = module.val_dataloader()\n",
    "batch = next(iter(loader))\n",
    "list(batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trajectory': tensor([[[[ 0.0000e+00, -1.4608e-03, -2.0801e-03,  ..., -2.8628e-01,\n",
       "            -2.8653e-01, -2.8676e-01],\n",
       "           [ 0.0000e+00, -2.5851e-04, -2.6852e-04,  ..., -7.0418e-02,\n",
       "            -7.0737e-02, -7.1097e-02],\n",
       "           [ 9.2889e-01,  9.2918e-01,  9.2991e-01,  ...,  7.2556e-01,\n",
       "             7.2503e-01,  7.2449e-01]],\n",
       " \n",
       "          [[ 3.1463e-02,  2.9694e-02,  2.8941e-02,  ..., -2.4621e-01,\n",
       "            -2.4644e-01, -2.4672e-01],\n",
       "           [-8.4738e-02, -8.5087e-02, -8.5188e-02,  ..., -1.5554e-01,\n",
       "            -1.5586e-01, -1.5622e-01],\n",
       "           [ 9.7729e-01,  9.7763e-01,  9.7829e-01,  ...,  7.6634e-01,\n",
       "             7.6578e-01,  7.6528e-01]],\n",
       " \n",
       "          [[-3.0521e-02, -3.2319e-02, -3.3269e-02,  ..., -3.1650e-01,\n",
       "            -3.1687e-01, -3.1718e-01],\n",
       "           [-9.0789e-02, -9.0961e-02, -9.0880e-02,  ..., -1.6001e-01,\n",
       "            -1.6033e-01, -1.6070e-01],\n",
       "           [ 8.7560e-01,  8.7595e-01,  8.7671e-01,  ...,  6.7012e-01,\n",
       "             6.6967e-01,  6.6918e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.9367e-02,  4.7657e-02,  4.1862e-02,  ..., -3.7691e-01,\n",
       "            -3.7749e-01, -3.7780e-01],\n",
       "           [ 2.5680e-01,  2.5524e-01,  2.5196e-01,  ...,  2.5269e-03,\n",
       "             2.4177e-03,  2.2538e-03],\n",
       "           [ 6.3416e-01,  6.3619e-01,  6.3815e-01,  ...,  5.5302e-01,\n",
       "             5.5302e-01,  5.5267e-01]],\n",
       " \n",
       "          [[-2.2248e-01, -2.2056e-01, -2.1678e-01,  ..., -2.7821e-01,\n",
       "            -2.7798e-01, -2.7808e-01],\n",
       "           [ 2.5612e-01,  2.5862e-01,  2.6300e-01,  ..., -1.0278e-01,\n",
       "            -1.0330e-01, -1.0384e-01],\n",
       "           [ 1.1340e+00,  1.1365e+00,  1.1409e+00,  ...,  9.0282e-01,\n",
       "             9.0208e-01,  9.0125e-01]],\n",
       " \n",
       "          [[-2.0024e-01, -2.0118e-01, -2.0469e-01,  ..., -4.5657e-01,\n",
       "            -4.5697e-01, -4.5723e-01],\n",
       "           [ 3.2046e-01,  3.2012e-01,  3.1903e-01,  ..., -2.3448e-01,\n",
       "            -2.3427e-01, -2.3417e-01],\n",
       "           [ 7.1251e-01,  7.1600e-01,  7.2308e-01,  ...,  6.5291e-01,\n",
       "             6.5382e-01,  6.5412e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000e+00, -1.4608e-03, -2.0801e-03,  ..., -2.8628e-01,\n",
       "            -2.8653e-01, -2.8676e-01],\n",
       "           [ 0.0000e+00, -2.5851e-04, -2.6852e-04,  ..., -7.0418e-02,\n",
       "            -7.0737e-02, -7.1097e-02],\n",
       "           [ 9.2889e-01,  9.2918e-01,  9.2991e-01,  ...,  7.2556e-01,\n",
       "             7.2503e-01,  7.2449e-01]],\n",
       " \n",
       "          [[ 3.1463e-02,  2.9694e-02,  2.8941e-02,  ..., -2.4621e-01,\n",
       "            -2.4644e-01, -2.4672e-01],\n",
       "           [-8.4738e-02, -8.5087e-02, -8.5188e-02,  ..., -1.5554e-01,\n",
       "            -1.5586e-01, -1.5622e-01],\n",
       "           [ 9.7729e-01,  9.7763e-01,  9.7829e-01,  ...,  7.6634e-01,\n",
       "             7.6578e-01,  7.6528e-01]],\n",
       " \n",
       "          [[-3.0521e-02, -3.2319e-02, -3.3269e-02,  ..., -3.1650e-01,\n",
       "            -3.1687e-01, -3.1718e-01],\n",
       "           [-9.0789e-02, -9.0961e-02, -9.0880e-02,  ..., -1.6001e-01,\n",
       "            -1.6033e-01, -1.6070e-01],\n",
       "           [ 8.7560e-01,  8.7595e-01,  8.7671e-01,  ...,  6.7012e-01,\n",
       "             6.6967e-01,  6.6918e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.9367e-02,  4.7657e-02,  4.1862e-02,  ..., -3.7691e-01,\n",
       "            -3.7749e-01, -3.7780e-01],\n",
       "           [ 2.5680e-01,  2.5524e-01,  2.5196e-01,  ...,  2.5269e-03,\n",
       "             2.4177e-03,  2.2538e-03],\n",
       "           [ 6.3416e-01,  6.3619e-01,  6.3815e-01,  ...,  5.5302e-01,\n",
       "             5.5302e-01,  5.5267e-01]],\n",
       " \n",
       "          [[-2.2248e-01, -2.2056e-01, -2.1678e-01,  ..., -2.7821e-01,\n",
       "            -2.7798e-01, -2.7808e-01],\n",
       "           [ 2.5612e-01,  2.5862e-01,  2.6300e-01,  ..., -1.0278e-01,\n",
       "            -1.0330e-01, -1.0384e-01],\n",
       "           [ 1.1340e+00,  1.1365e+00,  1.1409e+00,  ...,  9.0282e-01,\n",
       "             9.0208e-01,  9.0125e-01]],\n",
       " \n",
       "          [[-2.0024e-01, -2.0118e-01, -2.0469e-01,  ..., -4.5657e-01,\n",
       "            -4.5697e-01, -4.5723e-01],\n",
       "           [ 3.2046e-01,  3.2012e-01,  3.1903e-01,  ..., -2.3448e-01,\n",
       "            -2.3427e-01, -2.3417e-01],\n",
       "           [ 7.1251e-01,  7.1600e-01,  7.2308e-01,  ...,  6.5291e-01,\n",
       "             6.5382e-01,  6.5412e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000e+00,  4.9408e-04,  9.7823e-04,  ..., -1.3674e+00,\n",
       "            -1.3818e+00, -1.3959e+00],\n",
       "           [ 0.0000e+00, -3.9637e-04, -3.5584e-05,  ..., -3.6543e-02,\n",
       "            -3.4822e-02, -3.2310e-02],\n",
       "           [ 9.5755e-01,  9.5960e-01,  9.6153e-01,  ...,  8.5263e-01,\n",
       "             8.4828e-01,  8.4386e-01]],\n",
       " \n",
       "          [[ 5.1827e-02,  5.2434e-02,  5.2991e-02,  ..., -1.3511e+00,\n",
       "            -1.3658e+00, -1.3805e+00],\n",
       "           [-8.5905e-02, -8.6485e-02, -8.6055e-02,  ..., -1.2084e-01,\n",
       "            -1.1894e-01, -1.1619e-01],\n",
       "           [ 9.7872e-01,  9.7972e-01,  9.8176e-01,  ...,  9.0870e-01,\n",
       "             9.0470e-01,  9.0078e-01]],\n",
       " \n",
       "          [[-4.9595e-02, -5.0178e-02, -4.9704e-02,  ..., -1.3741e+00,\n",
       "            -1.3880e+00, -1.4012e+00],\n",
       "           [-8.8497e-02, -8.8704e-02, -8.8453e-02,  ..., -1.2752e-01,\n",
       "            -1.2598e-01, -1.2370e-01],\n",
       "           [ 9.1605e-01,  9.1901e-01,  9.2120e-01,  ...,  7.9187e-01,\n",
       "             7.8773e-01,  7.8358e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-8.6180e-02, -9.0320e-02, -9.0883e-02,  ..., -1.2228e+00,\n",
       "            -1.2378e+00, -1.2534e+00],\n",
       "           [ 1.8504e-01,  1.8455e-01,  1.8385e-01,  ...,  1.4590e-01,\n",
       "             1.4491e-01,  1.4456e-01],\n",
       "           [ 7.6742e-01,  7.7263e-01,  7.7450e-01,  ...,  6.4824e-01,\n",
       "             6.4300e-01,  6.3743e-01]],\n",
       " \n",
       "          [[ 1.7289e-01,  1.7433e-01,  1.7608e-01,  ..., -1.4479e+00,\n",
       "            -1.4597e+00, -1.4736e+00],\n",
       "           [-7.0376e-02, -7.1387e-02, -7.0555e-02,  ..., -1.0583e-01,\n",
       "            -1.0257e-01, -9.8724e-02],\n",
       "           [ 1.1611e+00,  1.1601e+00,  1.1604e+00,  ...,  1.1632e+00,\n",
       "             1.1580e+00,  1.1528e+00]],\n",
       " \n",
       "          [[-1.2666e-01, -1.3314e-01, -1.3359e-01,  ..., -1.2265e+00,\n",
       "            -1.2429e+00, -1.2608e+00],\n",
       "           [-7.6413e-02, -7.6815e-02, -7.8000e-02,  ..., -1.0869e-01,\n",
       "            -1.0961e-01, -1.0976e-01],\n",
       "           [ 7.1743e-01,  7.2411e-01,  7.2856e-01,  ...,  5.6070e-01,\n",
       "             5.5531e-01,  5.4933e-01]]]]),\n",
       " 'trajectory_rot6d': tensor([[[ 0.4416,  0.4399,  0.4398,  ..., -0.0138, -0.0159, -0.0182],\n",
       "          [ 0.2811,  0.1607,  0.2241,  ...,  0.2507,  0.2520,  0.2530],\n",
       "          [-0.0163, -0.0395, -0.0832,  ...,  0.0437,  0.0442,  0.0450],\n",
       "          ...,\n",
       "          [ 0.6818,  0.6632,  0.6192,  ..., -0.5039, -0.5080, -0.5126],\n",
       "          [-0.2683, -0.2940, -0.3249,  ..., -1.1525, -1.1517, -1.1565],\n",
       "          [ 1.5972,  1.6226,  1.6478,  ..., -2.1484, -2.1469, -2.1484]],\n",
       " \n",
       "         [[ 0.4416,  0.4399,  0.4398,  ..., -0.0138, -0.0159, -0.0182],\n",
       "          [ 0.2811,  0.1607,  0.2241,  ...,  0.2507,  0.2520,  0.2530],\n",
       "          [-0.0163, -0.0395, -0.0832,  ...,  0.0437,  0.0442,  0.0450],\n",
       "          ...,\n",
       "          [ 0.6818,  0.6632,  0.6192,  ..., -0.5039, -0.5080, -0.5126],\n",
       "          [-0.2683, -0.2940, -0.3249,  ..., -1.1525, -1.1517, -1.1565],\n",
       "          [ 1.5972,  1.6226,  1.6478,  ..., -2.1484, -2.1469, -2.1484]],\n",
       " \n",
       "         [[ 0.6269,  0.6244,  0.6267,  ...,  0.3906,  0.4017,  0.4180],\n",
       "          [ 0.3291,  0.3081,  0.3074,  ..., -0.8520, -0.8139, -0.7957],\n",
       "          [-0.0366, -0.2166, -0.2053,  ...,  0.4347,  0.4305,  0.4372],\n",
       "          ...,\n",
       "          [-0.1019, -0.0828, -0.0868,  ...,  0.2716,  0.2846,  0.3077],\n",
       "          [-0.7516, -0.7740, -0.7961,  ...,  0.4506,  0.4480,  0.4388],\n",
       "          [ 1.9484,  1.9724,  1.9762,  ...,  0.9834,  0.9836,  0.9923]]]),\n",
       " 'sample_id': tensor([0, 0, 3]),\n",
       " 'question_id': tensor([0, 4, 1]),\n",
       " 'action_sequence': {'start': [tensor([0., 0., 0.], dtype=torch.float64),\n",
       "   tensor([3., 3., 3.], dtype=torch.float64),\n",
       "   tensor([6., 6., 6.], dtype=torch.float64),\n",
       "   tensor([9., 9., 9.], dtype=torch.float64)],\n",
       "  'end': [tensor([3., 3., 3.], dtype=torch.float64),\n",
       "   tensor([6., 6., 6.], dtype=torch.float64),\n",
       "   tensor([9., 9., 9.], dtype=torch.float64),\n",
       "   tensor([12., 12., 12.], dtype=torch.float64)],\n",
       "  'action': [('boxing from left to right',\n",
       "    'boxing from left to right',\n",
       "    'stepping'),\n",
       "   ('praying', 'praying', 'stepping'),\n",
       "   ('listening', 'listening', 'stepping'),\n",
       "   ('praying', 'praying', 'waddling')],\n",
       "  'action_sentence': [('The person is starting off the sequence with boxing from left to right',\n",
       "    'The person is starting off the sequence with boxing from left to right',\n",
       "    'Stepping is the last action performed by the person'),\n",
       "   ('We see the person engaging in praying',\n",
       "    'We see the person engaging in praying',\n",
       "    'We see the person engaging in stepping'),\n",
       "   ('The movement is listening',\n",
       "    'The movement is listening',\n",
       "    'The person is stepping'),\n",
       "   ('The sequence finishes with praying',\n",
       "    'The sequence finishes with praying',\n",
       "    'Finally, the person is waddling')]},\n",
       " 'textual_description': ['The person is starting off the sequence with boxing from left to right. This action is starting at 0:0.0 and happens until 0:3.0, meaning the engagement in this is for 3.0 seconds. We see the person engaging in praying from 0:3.0 to 0:6.0 (for 3.0 seconds). The movement is listening at timestamp 0:6.0 and ending at 0:9.0, resulting in a total time of 3.0 seconds. The sequence finishes with praying. This action is starting at 0:9.0 and continues until 0:12.0, resulting in a total time of 3.0 seconds.',\n",
       "  'The person is starting off the sequence with boxing from left to right. This action is starting at 0:0.0 and happens until 0:3.0, meaning the engagement in this is for 3.0 seconds. We see the person engaging in praying from 0:3.0 to 0:6.0 (for 3.0 seconds). The movement is listening at timestamp 0:6.0 and ending at 0:9.0, resulting in a total time of 3.0 seconds. The sequence finishes with praying. This action is starting at 0:9.0 and continues until 0:12.0, resulting in a total time of 3.0 seconds.',\n",
       "  'Stepping is the last action performed by the person from 0:0.0 to 0:3.0 (3.0 seconds total). We see the person engaging in stepping. This action is starting at 0:3.0 and happens until 0:6.0, meaning the engagement in this is for 3.0 seconds. The person is stepping at timestamp 0:6.0 and ending at 0:9.0, resulting in a total time of 3.0 seconds. Finally, the person is waddling. It is starting at second 0:9.0 and continuing until 0:12.0, so the person is doing this for 3.0 seconds.'],\n",
       " 'question_type': ['last_multi', 'last_multi', 'count_number_multi'],\n",
       " 'question': ['Which activity can be identified as the very last action carried out by the person? Did they perform A: praying, B: ducking, or C: searching?',\n",
       "  'Among the given choices, what was the last action executed by the person? Was it A: playing guitar, B: crying, or C: crying?',\n",
       "  'Out of the available activities, which one does the person carry out 1 times? A: squatting, B: squatting, or C: stepping?'],\n",
       " 'answer_type': ['multi', 'multi', 'multi'],\n",
       " 'answer_text': ['The correct answer is: praying.',\n",
       "  'The correct answer is: praying.',\n",
       "  'The correct answer is stepping.'],\n",
       " 'options': {'A': ['praying', 'playing guitar', 'squatting'],\n",
       "  'B': ['ducking', 'crying', 'squatting'],\n",
       "  'C': ['searching', 'crying', 'stepping']},\n",
       " 'answer': tensor([0, 2, 2]),\n",
       " 'options_sequence': [('praying', 'playing guitar', 'squatting'),\n",
       "  ('ducking', 'crying', 'squatting'),\n",
       "  ('searching', 'crying', 'stepping')]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
